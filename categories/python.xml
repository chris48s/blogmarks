<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blogmarks (Posts about python)</title><link>https://chris48s.github.io/blogmarks/</link><description></description><atom:link href="https://chris48s.github.io/blogmarks/categories/python.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2024 chris48s</copyright><lastBuildDate>Thu, 22 Aug 2024 18:06:40 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>An analysis of python package manifest files</title><link>https://chris48s.github.io/blogmarks/posts/2024/python-package-manifest-files/</link><dc:creator>chris48s</dc:creator><description>&lt;p&gt;Python packaging is messy and fragmented. Lots of people have been writing about it recently and there have been some great articles that have attracted a lot of attention. For example, I've particularly enjoyed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://alpopkes.com/posts/python/packaging_tools/"&gt;An unbiased evaluation of environment management and packaging tools&lt;/a&gt; by Anna-Lena Popkes&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chriswarrick.com/blog/2023/01/15/how-to-improve-python-packaging/"&gt;How to improve Python packaging, or why fourteen tools are at least twelve too many&lt;/a&gt; by Chris Warrick and&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pradyunsg.me/blog/2023/01/21/thoughts-on-python-packaging/"&gt;Thoughts on the Python packaging ecosystem&lt;/a&gt; by Pradyun Gedam&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gregory Szorc also captured the frustrating experience many developers face trying to navigate the modern python packaging landscape in &lt;a href="https://gregoryszorc.com/blog/2023/10/30/my-user-experience-porting-off-setup.py/"&gt;My User Experience Porting Off setup.py&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is a topic I also spend a lot of time thinking about, but I decided to take a look at the topic from a slightly different angle. Instead of lamenting the proliferation of different tools, or attempting to round them all up and compare them, I decided to ask: What are package authors actually doing out there in the wild, and how is the community responding to this change and fragmentation?&lt;/p&gt;
&lt;p&gt;So I conducted a bit of research. I looked at a sample of 31,474 public GitHub repos associated with one or more python packages on PyPI and analysed the manifests to find out a bit more about how people are actually specifying their package metadata and building their packages. For the purposes of this research, I'm focussing on packages. You could probably ask and answer some similarly interesting questions about applications, but I haven't done it here. There's a bit more information about how and why I arrived at this sample of ~30k GitHub repos in the &lt;a href="https://chris48s.github.io/blogmarks/posts/2024/python-package-manifest-files/#methodology-notes"&gt;methodology notes&lt;/a&gt;, but I'm not going to bury the lead. Lets just jump straight into the good stuff.&lt;/p&gt;
&lt;h3&gt;Manifest files&lt;/h3&gt;
&lt;p&gt;I looked for the presence of 3 files: pyproject.toml, setup.py and setup.cfg. Most of the repos I looked at contained more than one.&lt;/p&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;File&lt;/th&gt;
    &lt;th&gt;Count&lt;/th&gt;
    &lt;th&gt;Percent&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;setup.py&lt;/td&gt;
    &lt;td class="right-align"&gt;20,684&lt;/td&gt;
    &lt;td class="percent" style="background-size: 66% 100%"&gt;66%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;pyproject.toml&lt;/td&gt;
    &lt;td class="right-align"&gt;17,245&lt;/td&gt;
    &lt;td class="percent" style="background-size: 55% 100%"&gt;55%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;setup.cfg&lt;/td&gt;
    &lt;td class="right-align"&gt;10,406&lt;/td&gt;
    &lt;td class="percent" style="background-size: 33% 100%"&gt;33%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Total&lt;/b&gt;&lt;/td&gt;
    &lt;td class="right-align"&gt;&lt;b&gt;31,474&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;-&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;h3&gt;Pyproject.toml&lt;/h3&gt;
&lt;p&gt;One of the big pushes in python is for adoption of pyproject.toml. So how is that going out there in the real world?&lt;/p&gt;
&lt;p&gt;First of all, it is worth reviewing some of the ways pyproject.toml is or can be used.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://peps.python.org/pep-0517/"&gt;PEP 517&lt;/a&gt; Defines a way to declare a package build backend in pyproject.toml.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://peps.python.org/pep-0621/"&gt;PEP 621&lt;/a&gt; Defines a way to define the package metadata in pyproject.toml.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://peps.python.org/pep-0518/"&gt;PEP 518&lt;/a&gt; Defines a way to declare package build requirements in pyproject.toml and a way for python tools (which may or may not be related to packaging) to store configuration in the &lt;code&gt;tool.*&lt;/code&gt; namespace. Many python tools like pytest, black, mypy, etc allow their configuration to be stored in pyproject.toml using the &lt;code&gt;tool.*&lt;/code&gt; namespace.&lt;/li&gt;
&lt;li&gt;In particular, poetry allows package metadata to be specified in pyproject.toml in a &lt;code&gt;tool.poetry&lt;/code&gt; declaration, but predates and does not conform to PEP 621. I'm going to consider poetry separately.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A point to note here is that these can be combined in various ways. For example, it is possible to declare a build backend in pyproject.toml following PEP 517 and also declare PEP 621 package metadata. However using setuptools it is also possible to declare a build backend in pyproject.toml but specify the rest of the package metadata in setup.py or setup.cfg. Some repos only use pyproject.toml for storing linter configuration and everything to do with packaging is stored in setup.py or setup.cfg. Some repos specify package metadata in pyproject.toml (either following PEP 621 or using poetry), but don't declare a build system. One does not necessarily imply another. I found examples of pretty much every combination. This makes it difficult to conduct a completely coherent analysis or arrive at universally valid assumptions.&lt;/p&gt;
&lt;p&gt;In the sample of repos I looked at 17,245 (55%) contained a pyproject.toml file. 15,754 (91%) of those declare a build backend, requirements, and/or package metadata. 1,497 (9%) did not contain any of those things. Presumably in basically all of those cases, pyproject.toml is being used exclusively as a configuration file for dev tooling.&lt;/p&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Feature&lt;/th&gt;
    &lt;th&gt;Count&lt;/th&gt;
    &lt;th&gt;Percent&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Has build requirements&lt;/td&gt;
    &lt;td class="right-align"&gt;15,427&lt;/td&gt;
    &lt;td class="percent" style="background-size: 89% 100%"&gt;89%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Has build backend&lt;/td&gt;
    &lt;td class="right-align"&gt;14,328&lt;/td&gt;
    &lt;td class="percent" style="background-size: 83% 100%"&gt;83%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Has PEP 621 metadata&lt;/td&gt;
    &lt;td class="right-align"&gt;6,563&lt;/td&gt;
    &lt;td class="percent" style="background-size: 38% 100%"&gt;38%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Has Poetry metadata&lt;/td&gt;
    &lt;td class="right-align"&gt;4,890&lt;/td&gt;
    &lt;td class="percent" style="background-size: 28% 100%"&gt;28%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Has no packaging metadata&lt;/td&gt;
    &lt;td class="right-align"&gt;1,497&lt;/td&gt;
    &lt;td class="percent" style="background-size: 9% 100%"&gt;9%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Total&lt;/b&gt;&lt;/td&gt;
    &lt;td class="right-align"&gt;&lt;b&gt;17,245&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;-&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;There are a few interesting results here. The first is that most repos containing a pyproject.toml declare either a build backend and/or requirements. I was actually surprised that more files declare build requirements than a build backend. I expected repos declaring build requirements would basically be a subset of those declaring a build backend. Turns out the inverse is true.&lt;/p&gt;
&lt;p&gt;Many repos are declaring package metadata in pyproject.toml using either PEP 621 or Poetry format, but adoption of pyproject.toml for this purpose is less common.&lt;/p&gt;
&lt;p&gt;My hunch is that a lot of the repos which are only specifying build backend/requirements may have adopted pyproject.toml primarily as a configuration format (as opposed to a package manifest format) and then added a minimal &lt;code&gt;build-system&lt;/code&gt; declaration for compatibility purposes. However that is just my conjecture.&lt;/p&gt;
&lt;h3&gt;Setup.py and setup.cfg&lt;/h3&gt;
&lt;p&gt;The oldest way to specify package metadata is using setup.py. This has served the community well for many years, but the package metadata is mixed with executable python code. The python community's first attempt at a declarative manifest format was setup.cfg. This was a format specific to setuptools rather than a standard and the setuptools project plans to &lt;a href="https://github.com/pypa/setuptools/issues/3214"&gt;eventually deprecate&lt;/a&gt; setup.cfg. One of the big pushes in python is for moving away from setup.py and setup.cfg to specify package metadata, and towards pyproject.toml. So how is that going out there in the real world?&lt;/p&gt;
&lt;p&gt;Of the repos I looked at, 20,684 (66%) contained a setup.py and 10,406 (33%) contained a setup.cfg file. Many contained both. As with pyproject.toml, presence or absence of the file in a repo doesn't necessarily tell us the full story. Some repos that are primarily using pyproject.toml also have a stub setup.py that just contains&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;setuptools&lt;/span&gt;
&lt;span class="n"&gt;setuptools&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;for backwards compatibility reasons. This may be needed, for example for compatibility with tools that don't support &lt;a href="https://peps.python.org/pep-0660/"&gt;PEP 660&lt;/a&gt; editable installs.&lt;/p&gt;
&lt;p&gt;As with pyproject.toml, many python based tools like isort and flake8 allow their configuration to be stored in setup.cfg so some repos contain a setup.cfg but aren't using to store any information related to packaging - it is just there to store linter configuration. Again, basically every combination of scenarios exists in the sample of repos I looked at.&lt;/p&gt;
&lt;p&gt;I haven't attempted to parse the setup.py and setup.cfg files. I am perhaps missing a bit of nuance here, but I have made some assumptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A repo which declares poetry or PEP 621 package metadata in pyproject.toml is using pyproject.toml as the package manifest.&lt;/li&gt;
&lt;li&gt;A repo that has a setup.py but not a setup.cfg and either doesn't have a pyproject.toml at all or has a pyproject.toml which does not contain poetry or PEP 621 package metadata is using setup.py as the package manifest.&lt;/li&gt;
&lt;li&gt;A repo that has a setup.py and setup.cfg and either doesn't have a pyproject.toml at all or has a pyproject.toml which does not contain poetry or PEP 621 package metadata is using setup.py or setup.cfg as the package manifest.&lt;/li&gt;
&lt;li&gt;There were also just over 1,000 repos doing some other combination of things. A lot of these were a pyproject.toml declaring a build system or build requirements only, with metadata in setup.cfg. I didn't attempt to break them down any further.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Manifest type&lt;/th&gt;
    &lt;th&gt;Count&lt;/th&gt;
    &lt;th&gt;Percent&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;pyproject.toml with metadata&lt;/td&gt;
    &lt;td class="right-align"&gt;11,349&lt;/td&gt;
    &lt;td class="percent" style="background-size: 36% 100%"&gt;36%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;setup.py only&lt;/td&gt;
    &lt;td class="right-align"&gt;10,695&lt;/td&gt;
    &lt;td class="percent" style="background-size: 34% 100%"&gt;34%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;setup.py and setup.cfg&lt;/td&gt;
    &lt;td class="right-align"&gt;8,235&lt;/td&gt;
    &lt;td class="percent" style="background-size: 26% 100%"&gt;26%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Other&lt;/td&gt;
    &lt;td class="right-align"&gt;1,195&lt;/td&gt;
    &lt;td class="percent" style="background-size: 4% 100%"&gt;4%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Total&lt;/b&gt;&lt;/td&gt;
    &lt;td class="right-align"&gt;&lt;b&gt;31,474&lt;/b&gt;&lt;/td&gt;
    &lt;td class="percent" style="background-size: 100% 100%"&gt;&lt;b&gt;100%&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;18,930 (63%) of the repos I looked at are sticking with setup.py and/or setup.cfg as the package manifest.&lt;/p&gt;
&lt;p&gt;Using only a setup.py is still a very popular method of packaging at 34%. This is nearly equal with storing package metadata in pyproject.toml at 36%, despite efforts to transition the community away from executable package manifests and towards declarative manifest formats.&lt;/p&gt;
&lt;h3&gt;Build Backends&lt;/h3&gt;
&lt;p&gt;14,328 of the repos I looked at are using a pyproject.toml that declares a PEP-517 build backend. So next I dug into that. Which build backends are these repos using?&lt;/p&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Build backend&lt;/th&gt;
    &lt;th&gt;Count&lt;/th&gt;
    &lt;th&gt;Percent&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Setuptools&lt;/td&gt;
    &lt;td class="right-align"&gt;6,732&lt;/td&gt;
    &lt;td class="percent" style="background-size: 47% 100%"&gt;47%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Poetry&lt;/td&gt;
    &lt;td class="right-align"&gt;4,671&lt;/td&gt;
    &lt;td class="percent" style="background-size: 33% 100%"&gt;33%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Hatch&lt;/td&gt;
    &lt;td class="right-align"&gt;1,592&lt;/td&gt;
    &lt;td class="percent" style="background-size: 11% 100%"&gt;11%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Flit&lt;/td&gt;
    &lt;td class="right-align"&gt;687&lt;/td&gt;
    &lt;td class="percent" style="background-size: 5% 100%"&gt;5%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Other&lt;/td&gt;
    &lt;td class="right-align"&gt;223&lt;/td&gt;
    &lt;td class="percent" style="background-size: 2% 100%"&gt;2%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Pdm&lt;/td&gt;
    &lt;td class="right-align"&gt;215&lt;/td&gt;
    &lt;td class="percent" style="background-size: 2% 100%"&gt;2%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Maturin&lt;/td&gt;
    &lt;td class="right-align"&gt;208&lt;/td&gt;
    &lt;td class="percent" style="background-size: 1% 100%"&gt;1%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Total&lt;/b&gt;&lt;/td&gt;
    &lt;td class="right-align"&gt;&lt;b&gt;14,328&lt;/b&gt;&lt;/td&gt;
    &lt;td class="percent" style="background-size: 100% 100%"&gt;&lt;b&gt;100%&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;There are more interesting findings here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Among repos using pyproject.toml, setuptools is the by far the most commonly declared build backend, accounting for nearly half the repos I looked at.&lt;/li&gt;
&lt;li&gt;New shiny tools like poetry, hatch and flit have some adoption, but account for a much smaller share of the ecosystem.&lt;/li&gt;
&lt;li&gt;By far the most widely used of these more modern packaging tools is poetry, accounting for 33% of the repos I looked at declaring a build backend in pyproject.toml.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Setuptools&lt;/h3&gt;
&lt;p&gt;Finally, I wanted to look at those repos using setuptools and pyproject.toml. Broadly, these are going to divide into 2 camps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Those specifying package metadata in pyproject.toml, following PEP-621&lt;/li&gt;
&lt;li&gt;Those specifying a build backend only in pyproject.toml, following PEP-517, but storing the package metadata in setup.py or setup.cfg.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Metadata location&lt;/th&gt;
    &lt;th&gt;Count&lt;/th&gt;
    &lt;th&gt;Percent&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Outside pyproject.toml&lt;/td&gt;
    &lt;td class="right-align"&gt;3,615&lt;/td&gt;
    &lt;td class="percent" style="background-size: 54% 100%"&gt;54%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Inside pyproject.toml (PEP-621)&lt;/td&gt;
    &lt;td class="right-align"&gt;3,117&lt;/td&gt;
    &lt;td class="percent" style="background-size: 46% 100%"&gt;46%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Total&lt;/b&gt;&lt;/td&gt;
    &lt;td class="right-align"&gt;&lt;b&gt;6,732&lt;/b&gt;&lt;/td&gt;
    &lt;td class="percent" style="background-size: 100% 100%"&gt;&lt;b&gt;100%&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Among repos using setuptools and pyproject.toml, only a minority have adopted PEP-621 for declaring package metadata. In the sample of repos I looked at which declare setuptools as a build backend in pyproject.toml, the most popular approach (albeit by a small margin) is to declare only the build backend details in pyproject.toml and store the package metadata elsewhere.&lt;/p&gt;
&lt;h3&gt;Conclusions&lt;/h3&gt;
&lt;p&gt;Based on the analysis I've done here, it seems reasonable to say that adoption of pyproject.toml has been slow, particularly as a package manifest format. Most of the repos I looked at are only or primarily using setup.py and/or setup.cfg. Modern packaging tools are generating blog posts, debate, and mindshare. Out there in the real world we are seeing limited adoption in comparison to more traditional approaches. While a blog post about setuptools is less likely to hit the front page of hackernews, setuptools is the real workhorse when it comes to getting packages shipped.&lt;/p&gt;
&lt;p&gt;As noted at the start of this article, python packaging is a confusing and fragmented space at the moment. There are a lot of ways to skin this cat. It seems reasonable to infer that as a response to this, many developers are choosing to stick with an existing working solution, rather than make sense of the chaos. Who can blame them?&lt;/p&gt;
&lt;p&gt;The python community often moves slowly in response to change. For example the migration from python 2 to 3 dragged on for about a decade, but in that case the direction of travel was at least clear. There was a single linear path. When it comes to modernizing the packaging space, progress is also hindered by the fact that for some projects there are many possible directions of travel. For some projects, there are still zero. Perhaps this is a journey that will take even longer to shake out.&lt;/p&gt;
&lt;h3 id="methodology-notes"&gt;Methodology notes&lt;/h3&gt;

&lt;p&gt;This research was based on a convenience sample. I looked at a selection of repos that made it quick and easy to harvest data, rather than the most robust sample or a complete census of PyPI.&lt;/p&gt;
&lt;p&gt;As a starting point, I used the 2023-10-22 &lt;a href="https://packages.ecosyste.ms/open-data"&gt;Ecosyste.ms Open Data&lt;/a&gt; Release (which is licensed under &lt;a href="https://creativecommons.org/licenses/by-sa/4.0/"&gt;CC BY-SA 4.0&lt;/a&gt; ). This was an easy place to get a bulk list of python packages with GitHub repos attached. I then applied a few filters.&lt;/p&gt;
&lt;p&gt;First I excluded any packages which didn't have one or more releases published inside 2023. I'm really looking into modern packaging practices, so packages without a recent release are less useful to consider here.&lt;/p&gt;
&lt;p&gt;Then I excluded any packages that had less than 100 downloads in the last month. There is a lot of junk on PyPI. This is a low bar for popularity, but I wanted to apply some kind of measure of "someone is actually using this code for something". Applying even this modest filter excluded a surprisingly large number of packages.&lt;/p&gt;
&lt;p&gt;Then finally, I looked only at packages which had a GitHub repo attached to them in the Ecosyste.ms data. This was mainly about making it easy to fetch data in bulk. This means I excluded repos hosted on GitLab, BitBucket, CodeBerg, etc from this analysis. I also did not attempt to look at packages that had no &lt;code&gt;repository_url&lt;/code&gt; attached in the data. As such, the sample contains some blind spots.&lt;/p&gt;
&lt;p&gt;After de-duplicating, this gave me 35,732 GitHub repository URLs.&lt;/p&gt;
&lt;p&gt;I then used the GitHub GraphQL API to attempt to fetch a setup.py, setup.cfg and pyproject.toml if they existed in the repo root. After excluding any repos that were private, did not exist at all, or repos that didn't contain any of those files in the root, I was left with the 31,474 repos that formed the basis of this analysis. Another obvious blind spot here is repos that host a package in a subdirectory instead of the repo root. Those will have been excluded too.&lt;/p&gt;
&lt;p&gt;Finally, I grabbed whatever files were at the &lt;code&gt;HEAD&lt;/code&gt; of the default branch in GitHub. I didn't attempt to find a latest release, or the release that would have been current at the time of the ecosyste.ms open data release. I don't think this makes a huge difference, but it is worth noting.&lt;/p&gt;
&lt;h3&gt;Future work&lt;/h3&gt;
&lt;p&gt;This has been an interesting process, but it only represents a snapshot in a landscape that is shifting over time. I'd like to repeat this analysis again in future to see how the things have changed. It's been a blast. Let's do it again some time.&lt;/p&gt;</description><category>python</category><guid>https://chris48s.github.io/blogmarks/posts/2024/python-package-manifest-files/</guid><pubDate>Sat, 17 Feb 2024 00:00:00 GMT</pubDate></item><item><title>Arq and TaskIQ</title><link>https://chris48s.github.io/blogmarks/posts/2024/arq-taskiq/</link><dc:creator>chris48s</dc:creator><description>&lt;p&gt;At work, we recently found ourselves in the market for an asynchronous task queue for python. A traditional task queue like Celery can be said to be "asynchronous" in the sense that your web server can kick a task into the queue and continue processing the web request without waiting for the task to complete. However it is "synchronous" in the sense that the task functions in your queue must be synchronous functions (declared with &lt;code&gt;def&lt;/code&gt; rather than &lt;code&gt;async def&lt;/code&gt;). If you want to queue an &lt;code&gt;async&lt;/code&gt; function, you need an async worker to process it.&lt;/p&gt;
&lt;p&gt;The two contenders we've been looking at in this space are &lt;a href="https://arq-docs.helpmanual.io/"&gt;arq&lt;/a&gt; and &lt;a href="https://taskiq-python.github.io/"&gt;taskiq&lt;/a&gt;. These two solutions take slightly different approaches to solving the same problem.&lt;/p&gt;
&lt;p&gt;Taskiq takes a conceptually simple push/pop approach to interacting with the queue. This is the same model used by popular synchronous packages like Celery and rq. When a worker is free to take a task, it pops a task off the queue and then executes it. The downside of this approach is that if a worker pops a task off the queue and then shuts down without processing the task to completion, that task is already gone from your queue without having been run to completion. Another worker can't try it again.&lt;/p&gt;
&lt;p&gt;Arq takes a different approach called "pessimistic execution" which solves that specific problem. When an arq worker takes a task from the queue, it doesn't remove it from the queue yet. The task stays in the queue while it is being run. The task is finally deleted from the queue in a post hook after the task is complete. This means a task is only removed from the queue after it has run to completion.&lt;/p&gt;
&lt;p&gt;In order to ensure every worker in your cluster is not trying to process the same task at once, arq also maintains some additional shared state. When a worker takes a task, the worker acquires a lock on a task. That lock is automatically set to release after a timeout. If a worker never deletes the task in the post hook, the task is eventually unlocked and becomes available for another worker to process at a later time once the timeout expires.&lt;/p&gt;
&lt;p&gt;This gives arq some slightly different characteristics than taskiq.&lt;/p&gt;
&lt;p&gt;Arq will ideally try to deliver your task exactly once, but guarantees "at least once execution". Executing your task multiple times is considered preferable to executing it zero times. This means no lost tasks, but it also means if you use arq, your tasks must be written to be idempotent.&lt;/p&gt;
&lt;p&gt;The simple push/pop relationship with the queue employed by taskiq lends itself to being compatible with a wide range of backends. Taskiq already has plugins for using NATS, Redis, RabbitMQ and Kafka as brokers. Taskiq defines a &lt;a href="https://taskiq-python.github.io/extending-taskiq/broker.html"&gt;plugin interface&lt;/a&gt; for brokers, so it would be possible to write plugins for aditional backends like SQS for example.&lt;/p&gt;
&lt;p&gt;Conversely, arq has a more complicated relationship with the data store. The additional shared state required to implement the locking behaviour needs a richer set of operations. As such, arq is tightly coupled to redis as a backend. There is no mechanism to substitute another broker.&lt;/p&gt;
&lt;p&gt;So here's a summary of those tradeoffs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Arq is tied to redis. It provides stronger guarantees about eventual task execution and requires you to write your tasks with the assumption they could be attempted multiple times.&lt;/li&gt;
&lt;li&gt;Taskiq follows a model similar to Celery or rq. It provides weaker assurances, but this conceptually simpler model means you can assume your tasks will only be executed once. This setup also allows for compatibility with a wider range of brokers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our project has a lot of long-running tasks, which are vulnerable to being killed off before running to completion by deploy or scale-in events. Because of this, we prefer the pessimistic execution model offered by arq. We ended up moving forward with arq for our project.&lt;/p&gt;</description><category>python</category><guid>https://chris48s.github.io/blogmarks/posts/2024/arq-taskiq/</guid><pubDate>Thu, 18 Jan 2024 00:00:00 GMT</pubDate></item><item><title>Adding a custom tag to a Sentry event</title><link>https://chris48s.github.io/blogmarks/posts/2023/sentry-decorator/</link><dc:creator>chris48s</dc:creator><description>&lt;p&gt;Sentry allows you to enrich captured events by applying
&lt;a href="https://docs.sentry.io/product/sentry-basics/integrate-backend/capturing-errors/#enriching-your-event-data"&gt;custom tags and attributes&lt;/a&gt;.
I was recently working on a python application where I needed a re-usable
abstraction to express the logic "if function X throws exception Y
then apply this custom &lt;code&gt;key=value&lt;/code&gt; tag when we log the exception to Sentry"
in a bunch of places. Here's what I came up with:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;wraps&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sentry_sdk&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;capture_exception&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;push_scope&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tag_error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;exc_class&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;decorator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fn&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="nd"&gt;@wraps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;fn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ne"&gt;SystemExit&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="k"&gt;raise&lt;/span&gt;
            &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;exc_class&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;push_scope&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;scope&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;scope&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                        &lt;span class="n"&gt;capture_exception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;raise&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;wrapper&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;decorator&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This gives us a &lt;code&gt;@tag_error&lt;/code&gt; decorator, which can be applied to any function. For example:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="nd"&gt;@tag_error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"custom-key"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"custom-value"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;do_a_thing&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Oh no. A terrible thing has happened."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will tag any &lt;code&gt;ValueError&lt;/code&gt;s raised by calling &lt;code&gt;do_a_thing()&lt;/code&gt; with
&lt;code&gt;custom-key=custom-value&lt;/code&gt; when we log the exception to sentry.&lt;/p&gt;</description><category>python</category><guid>https://chris48s.github.io/blogmarks/posts/2023/sentry-decorator/</guid><pubDate>Sun, 28 May 2023 23:00:00 GMT</pubDate></item><item><title>Diagrams</title><link>https://chris48s.github.io/blogmarks/posts/2022/diagrams/</link><dc:creator>chris48s</dc:creator><description>&lt;p&gt;Last week I tried out &lt;a href="https://diagrams.mingrammer.com/"&gt;diagrams&lt;/a&gt; to knock up some cloud infrastructure diagrams. There are several things I really like about this tool:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The learning curve is very easy. I was able to absorb the key concepts and produce a useful diagram showing the AWS setup for an application I am working on within about 30 mins of installing it for the first time.&lt;/li&gt;
&lt;li&gt;The [effort in]:[pretty pictures out] ratio is very satisfying.&lt;/li&gt;
&lt;li&gt;Because the diagram is generated from code, it can live in your repo. The diff changing the diagram could be in the same commit as the updates to your CDK definitions or ansible playbooks or whatever it is that actually makes the infrastructure changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, the following diagram&lt;/p&gt;
&lt;p&gt;&lt;img alt="example diagram" src="https://chris48s.github.io/blogmarks/images/diagram.png"&gt;&lt;/p&gt;
&lt;p&gt;is generated from this short python snippet:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;diagrams&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Diagram&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;diagrams.aws.compute&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Fargate&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;diagrams.aws.database&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RDS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ElastiCache&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;diagrams.aws.engagement&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SES&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;diagrams.aws.network&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ELB&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Route53&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;diagrams.aws.storage&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;S3&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;Diagram&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;ses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SES&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Mail Transport (SES)"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;dns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Route53&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Route 53 (DNS)"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;s3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;S3&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"S3"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"VPC"&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;lb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ELB&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Load Balancer (ALB)"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;elasticache&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ElastiCache&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Redis (ElastiCache)"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"ECS"&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;web&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Fargate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"web"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;Cluster&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"DB Cluster (RDS)"&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;db_primary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RDS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"primary"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;db_primary&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;RDS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"read replica"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;dns&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;lb&lt;/span&gt;
    &lt;span class="n"&gt;lb&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;web&lt;/span&gt;

    &lt;span class="n"&gt;web&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;elasticache&lt;/span&gt;
    &lt;span class="n"&gt;web&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;db_primary&lt;/span&gt;
    &lt;span class="n"&gt;web&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;s3&lt;/span&gt;
    &lt;span class="n"&gt;web&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;ses&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><category>devops</category><category>python</category><guid>https://chris48s.github.io/blogmarks/posts/2022/diagrams/</guid><pubDate>Sat, 17 Sep 2022 23:00:00 GMT</pubDate></item><item><title>Three Rich tips</title><link>https://chris48s.github.io/blogmarks/posts/2022/rich-tips/</link><dc:creator>chris48s</dc:creator><description>&lt;p&gt;I've mentioned Will McGugan's excellent library &lt;a href="https://github.com/willmcgugan/rich"&gt;Rich&lt;/a&gt; on this blog before. It is a great tool for building nice terminal interfaces, but it is also an important local development tool. Here's three top tips:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Rich can be registered as a &lt;a href="https://rich.readthedocs.io/en/stable/traceback.html#traceback-handler"&gt;handler to render stacktraces&lt;/a&gt;. As well as the aesthetics, using Rich to handle stacktraces like this provides additional context which improves the usefulness of error messages in comparison to python's default handler.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Textualize/rich#rich-inspect"&gt;Rich.inspect&lt;/a&gt; can be used to examine a python object at runtime. I used to use &lt;code&gt;dir()&lt;/code&gt; or &lt;code&gt;vars()&lt;/code&gt; for this, but &lt;code&gt;rich.inspect()&lt;/code&gt; is a big step up.&lt;/li&gt;
&lt;li&gt;Rich can be used as a log handler. &lt;a href="https://rich.readthedocs.io/en/stable/logging.html"&gt;The docs&lt;/a&gt; cover how to use it with python's &lt;code&gt;logging&lt;/code&gt; module, but Will has also published this &lt;a href="https://www.willmcgugan.com/blog/tech/post/richer-django-logging/"&gt;blog post&lt;/a&gt; showing how to configure Django to use Rich as the default log handler.&lt;/li&gt;
&lt;/ol&gt;</description><category>python</category><category>terminal</category><guid>https://chris48s.github.io/blogmarks/posts/2022/rich-tips/</guid><pubDate>Sun, 13 Feb 2022 00:00:00 GMT</pubDate></item><item><title>Capturing stdout in python</title><link>https://chris48s.github.io/blogmarks/posts/2021/redirect-stdout/</link><dc:creator>chris48s</dc:creator><description>&lt;p&gt;Sometimes it is helpful to capture stdout/stderr. I usually use this when writing tests to make assertions about terminal output or just suppress it when the tests are running. Normally I would do a little switcheroo like this to manually manipulate &lt;code&gt;sys.stdout&lt;/code&gt;:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;io&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StringIO&lt;/span&gt; 
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;StringIO&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'foobar'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getvalue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__stdout__&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;but today I leaned about python's &lt;a href="https://docs.python.org/3/library/contextlib.html#contextlib.redirect_stdout"&gt;&lt;code&gt;contextlib.redirect_stdout&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://docs.python.org/3/library/contextlib.html#contextlib.redirect_stderr"&gt;&lt;code&gt;contextlib.redirect_stderr&lt;/code&gt;&lt;/a&gt;. These standard library context managers provide a built-in abstraction over this operation:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;io&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StringIO&lt;/span&gt; 
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;contextlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;redirect_stdout&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;StringIO&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;redirect_stdout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'foobar'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;buf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getvalue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><category>python</category><category>testing</category><guid>https://chris48s.github.io/blogmarks/posts/2021/redirect-stdout/</guid><pubDate>Thu, 18 Feb 2021 00:00:00 GMT</pubDate></item><item><title>Failing the CI build if django migrations are out of date</title><link>https://chris48s.github.io/blogmarks/posts/2021/check-migrations/</link><dc:creator>chris48s</dc:creator><description>&lt;p&gt;A common mistake in django is to make a model change but forget to run &lt;code&gt;makemigrations&lt;/code&gt; to generate a migration for the model change. Sometimes it is not entirely obvious when this need to happen. For example, let's say I'm using the &lt;a href="https://github.com/django-extensions/django-extensions"&gt;django-extensions&lt;/a&gt; library and I define a model like:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="c1"&gt;# models.py&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django_extensions.db.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TimeStampedModel&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MyModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TimeStampedModel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this situation, upgrading django-extensions to a new version might require me to regenerate the migrations in my app, even though I haven't made any changes to &lt;code&gt;models.py&lt;/code&gt; and overlooking this could generate unexpected results.&lt;/p&gt;
&lt;p&gt;Fortunately there is a simple thing I can do to detect and warn if this happens: If I run&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;python&lt;span class="w"&gt; &lt;/span&gt;manage.py&lt;span class="w"&gt; &lt;/span&gt;makemigrations&lt;span class="w"&gt; &lt;/span&gt;--check
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;in my CI build, this will cause the build to fail if my migrations are out of sync with the models, warning me about the problem.&lt;/p&gt;</description><category>python</category><guid>https://chris48s.github.io/blogmarks/posts/2021/check-migrations/</guid><pubDate>Wed, 10 Feb 2021 00:00:00 GMT</pubDate></item><item><title>Changing the tyres while the car is moving</title><link>https://chris48s.github.io/blogmarks/posts/2021/changing-the-tyres/</link><dc:creator>chris48s</dc:creator><description>&lt;p&gt;I am currently working on a project where I need to migrate a legacy test suite from nose to pytest. The codebase has about 7,000 lines of test code. That isn't an enormous test suite, but I'm the only person who will be working on it. It will take me a while to get through them all because moving from one test runner to another will require changes to fixtures, factories, etc and maybe some light codebase refactoring as well as just reviewing/updating the test code itself. I also need to balance this with continuing to deliver bugfix and feature work. I can't block all delivery on the test suite migration, so here's a pattern:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Split the test suite into two dirs: &lt;code&gt;/tests/nose&lt;/code&gt; and &lt;code&gt;/tests/pt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Migrate one module of test code at a time&lt;/li&gt;
&lt;li&gt;Have the CI build run the old tests with nose and the new ones with pytest and merge the coverage reports:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Run nose tests&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p p-Indicator"&gt;|&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="no"&gt;nosetests&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="no"&gt;--with-coverage \&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="no"&gt;--cover-package=dir \&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="no"&gt;--cover-erase \&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="no"&gt;path/to/tests/nose&lt;/span&gt;

&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Run pytest tests&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p p-Indicator"&gt;|&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="no"&gt;pytest \&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="no"&gt;--cov=dir \&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="no"&gt;--cov-append \&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="no"&gt;path/to/tests/pt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;When I rewrite the last test module left in &lt;code&gt;/tests/nose&lt;/code&gt;, we can finally drop nose, delete any nose-specific test helpers and move all the tests from &lt;code&gt;/tests/pt&lt;/code&gt; back to &lt;code&gt;/tests&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This approach buys me several useful things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I can tackle the test suite migration one module at a time&lt;/li&gt;
&lt;li&gt;I can submit small pull requests that are easy to review&lt;/li&gt;
&lt;li&gt;I can start writing tests for any new features or bugfixes in pytest right now&lt;/li&gt;
&lt;li&gt;I can minimise the chance of conflicts between test suite migration and bugfix/feature delivery&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a very simple example of a high-level general pattern for managing non-trivial migrations (like moving a project from one web framework to another). This can be applied to larger more complex migrations and enables us to "change the tyres while the car is moving" (a phrase I stole from my colleague &lt;a href="https://amercader.net/"&gt;AdriÃ &lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set up a structure that allows both &lt;code&gt;$OLD_BORING_THING&lt;/code&gt; and &lt;code&gt;$NEW_SHINY_THING&lt;/code&gt; to run at the same time&lt;/li&gt;
&lt;li&gt;Gradually move code from &lt;code&gt;$OLD_BORING_THING&lt;/code&gt; to &lt;code&gt;$NEW_SHINY_THING&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;When we migrate the last bit of code from &lt;code&gt;$OLD_BORING_THING&lt;/code&gt; to &lt;code&gt;$NEW_SHINY_THING&lt;/code&gt;, remove the structure that allows &lt;code&gt;$OLD_BORING_THING&lt;/code&gt; and &lt;code&gt;$NEW_SHINY_THING&lt;/code&gt; to co-exist and delete &lt;code&gt;$OLD_BORING_THING&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Continue to deliver our roadmap in parallel to the migration&lt;/li&gt;
&lt;/ul&gt;</description><category>python</category><category>testing</category><guid>https://chris48s.github.io/blogmarks/posts/2021/changing-the-tyres/</guid><pubDate>Sun, 31 Jan 2021 00:00:00 GMT</pubDate></item><item><title>A python CLI app which accepts input from stdin or a file</title><link>https://chris48s.github.io/blogmarks/posts/2020/stdin-or-file/</link><dc:creator>chris48s</dc:creator><description>&lt;p&gt;This excellent guide on &lt;a href="https://clig.dev/"&gt;Command Line Interface Guidelines&lt;/a&gt; has been shared widely over the last few days and it includes a huge variety of advice on writing elegant and well-behaved command line tools. The whole thing is well worth a read, but I'm going to pick out one quote to focus on in this post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;If your command is expecting to have something piped to it and stdin is an interactive terminal, display help immediately and quit.&lt;/strong&gt; This means it doesn't just hang, like &lt;code&gt;cat&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Tools that can optionally accept input via pipe are very useful and this pattern is entirely possible with python and argparse, but not completely obvious. Here's a simple example of a python program which:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can accept input as a file: &lt;code&gt;./myscript.py /path/to/file.txt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Can accept input via a pipe: &lt;code&gt;echo 'foo' | ./myscript.py&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Will print help and exit if invoked interactively with no arguments: &lt;code&gt;./myscript.py&lt;/code&gt; (instead of just hanging and waiting for input)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="ch"&gt;#!/usr/bin/env python3&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'A well-behaved CLI app which accepts input from stdin or a file'&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="s1"&gt;'file'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;nargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'?'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Input file, if empty stdin is used'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FileType&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isatty&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_help&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><category>python</category><category>terminal</category><guid>https://chris48s.github.io/blogmarks/posts/2020/stdin-or-file/</guid><pubDate>Mon, 07 Dec 2020 00:00:00 GMT</pubDate></item><item><title>pip 20.3</title><link>https://chris48s.github.io/blogmarks/posts/2020/pip-203/</link><dc:creator>chris48s</dc:creator><description>&lt;p&gt;There is a very long-standing issue on the pip repository: &lt;a href="https://github.com/pypa/pip/issues/988"&gt;pip needs a dependency resolver&lt;/a&gt;. Most language package managers (e.g: composer, bundler, cargo, etc) either use a resolver to derive a consistent dependency tree and prevent incompatible installations, or in the case of NPM/yarn allow "broken diamond" resolution (where more than one version of the same package can be installed at the same time). For the longest time, pip has had no true resolver, allowing incompatible dependencies to be installed. Until now..&lt;/p&gt;
&lt;p&gt;Today's release of &lt;a href="https://blog.python.org/2020/11/pip-20-3-release-new-resolver.html"&gt;Pip 20.3&lt;/a&gt; is the culmination of a &lt;a href="https://pyfound.blogspot.com/2020/03/new-pip-resolver-to-roll-out-this-year.html"&gt;long programme of work&lt;/a&gt; to implement a proper dependency resolver in pip. This makes pip 20.3 the most significant pip release in a very long time, possibly ever.&lt;/p&gt;
&lt;p&gt;It has actually been possible to preview this feature for some time using the &lt;code&gt;--use-feature=2020-resolver&lt;/code&gt; flag in pip 20.2.x or by installing the beta releases of pip 20.3, but pip 20.3 is the first stable release to enable the new resolver by default. This means that a command like:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;virtualenv&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;.0.2&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;six&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.11
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;or&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="nb"&gt;printf&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"virtualenv==20.0.2\nsix==1.11"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;requirements.txt
pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="w"&gt; &lt;/span&gt;requirements.txt
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;will now not install any new packages and throw a helpful error like:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;ERROR: Cannot install six==1.11 and virtualenv==20.0.2 because these package versions have conflicting dependencies.

The conflict is caused by:
    The user requested six==1.11
    virtualenv 20.0.2 depends on six&amp;lt;2 and &amp;gt;=1.12.0

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency conflict

ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;which is a &lt;em&gt;massive&lt;/em&gt; improvement over the previous behaviour. There is a gotcha though. Resolution only considers the packages being installed in that command. It doesn't take into account other packages already installed in your (virtual) environment. This means running&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;virtualenv&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;.0.2&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;six&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.11
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;doesn't fail to install &lt;code&gt;six==1.11&lt;/code&gt; with a &lt;code&gt;ResolutionImpossible&lt;/code&gt; error. It will still install the incompatible package and warn you that it has done that:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
ERROR: virtualenv 20.0.2 requires six&amp;lt;2,&amp;gt;=1.12.0, but you'll have six 1.11.0 which is incompatible.
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This isn't a bug. This behaviour is noted in the error message  and &lt;a href="https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-3-2020"&gt;documented in the release notes&lt;/a&gt;, but it is worth understanding this limitation. Even with the new resolver pip will still install incompatible dependencies in your environment if given the right combination of commands. This is a situation it is possible to wander into without realising or consciously enabling the legacy behaviour with &lt;code&gt;--use-deprecated=legacy-resolver&lt;/code&gt;. While it is useful to have some further improved messaging around this, it is still a bit of a disappointment.&lt;/p&gt;
&lt;p&gt;I've &lt;a href="https://chris48s.github.io/blogmarks/posts/2020/2poetry/"&gt;previously written&lt;/a&gt; about poetry. I'm now using poetry for all projects where I'm the only person who works on it and I have no plan to change that (poetry's behaviour is still more advanced here and IMO preferable), but it is impossible to work in the wider python community without encountering pip. This feature reduces that point of friction and it is great to see, but it isn't a silver bullet for preventing incompatible dependencies. It will be interesting to see how the wider community responds as users encounter this behaviour change for the first time.&lt;/p&gt;</description><category>packaging</category><category>python</category><guid>https://chris48s.github.io/blogmarks/posts/2020/pip-203/</guid><pubDate>Mon, 30 Nov 2020 00:00:00 GMT</pubDate></item></channel></rss>